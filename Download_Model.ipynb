{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ac3a19-29c9-4598-96b2-ae176a75f4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'CMAKE_ARGS' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.17.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2023.11.17)\n",
      "Collecting llama-cpp-python==0.1.78\n",
      "  Downloading llama_cpp_python-0.1.78.tar.gz (1.7 MB)\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.2/1.7 MB 5.9 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 0.8/1.7 MB 10.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 15.4 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from llama-cpp-python==0.1.78) (4.9.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from llama-cpp-python==0.1.78) (1.26.3)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.1.78)\n",
      "  Obtaining dependency information for diskcache>=5.6.1 from https://files.pythonhosted.org/packages/3f/27/4570e78fc0bf5ea0ca45eb1de3818a23787af9b390c0b0a0033a1b8236f9/diskcache-5.6.3-py3-none-any.whl.metadata\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.5/45.5 kB ? eta 0:00:00\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.78-cp311-cp311-win_amd64.whl size=1156209 sha256=4f5645d840a96a011c38ad1f822245a5754360316d2bd7d6641848b64b1513a7\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\18\\69\\ad\\9b1cec6b18fe403616b8cfbf10021d1939cba077cee285c5c3\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: diskcache, llama-cpp-python\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.1.78\n",
      "Collecting numpy==1.23.4\n",
      "  Obtaining dependency information for numpy==1.23.4 from https://files.pythonhosted.org/packages/eb/a6/a3217b371207622bda002820da4f7e1332a96c8331dd4720c6d4be13a799/numpy-1.23.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading numpy-1.23.4-cp311-cp311-win_amd64.whl.metadata (2.3 kB)\n",
      "Downloading numpy-1.23.4-cp311-cp311-win_amd64.whl (14.6 MB)\n",
      "   ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.6 MB 660.6 kB/s eta 0:00:23\n",
      "    --------------------------------------- 0.2/14.6 MB 2.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.8/14.6 MB 7.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.5/14.6 MB 16.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.0/14.6 MB 16.2 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.1/14.6 MB 15.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.1/14.6 MB 15.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.1/14.6 MB 15.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.1/14.6 MB 15.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.6/14.6 MB 8.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.1/14.6 MB 11.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.6/14.6 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.1/14.6 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.1/14.6 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.1/14.6 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.3/14.6 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.9/14.6 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 7.5/14.6 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.0/14.6 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.4/14.6 MB 10.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.6/14.6 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.1/14.6 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.1/14.6 MB 11.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.6/14.6 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.1/14.6 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.1/14.6 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.1/14.6 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.3/14.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.7/14.6 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.6 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.6/14.6 MB 11.1 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.3\n",
      "    Uninstalling numpy-1.26.3:\n",
      "      Successfully uninstalled numpy-1.26.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Admin\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy\\\\core\\\\_multiarray_tests.cp311-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GPU llama-cpp-python\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 numpy==1.23.4 --force-reinstall --upgrade --no-cache-dir --verbose\n",
    "!pip install huggingface_hub\n",
    "!pip install llama-cpp-python==0.1.78\n",
    "!pip install numpy==1.23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "312fb827-bd15-4b95-9a36-dddc645410a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Llama-2-7B-Chat-GGML\"\n",
    "model_basename = \"llama-2-7b-chat.ggmlv3.q4_0.bin\" # the model is in bin format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0ce2dd-def0-411c-a989-6e8411f8a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f4f1dfa-0c72-40a1-b3f0-680f3b1d5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfd4e457-b129-4500-870c-74ad0c7b5b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7c2a17d73e44bfa538a8a682409950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)chat.ggmlv3.q4_0.bin:   0%|          | 0.00/3.79G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "335ea63a-373c-4fdf-b171-8b585d21b672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Admin\\\\.cache\\\\huggingface\\\\hub\\\\models--TheBloke--Llama-2-7B-Chat-GGML\\\\snapshots\\\\76cd63c351ae389e1d4b91cab2cf470aab11864b\\\\llama-2-7b-chat.ggmlv3.q4_0.bin'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3230e102-031a-46d3-8609-5527a3e1c7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
